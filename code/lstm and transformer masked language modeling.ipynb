{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad03035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 14:11:58.897405: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b73e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get preprocessed data:\n",
    "train_file = '../preprocessed_texts.txt'\n",
    "file = open(train_file, \"r\")\n",
    "\n",
    "train_data = file.read()\n",
    "train_data = train_data.split(' ')\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e97aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocabulary:\n",
    "with open('../vocabulary.pkl', 'rb') as fp:\n",
    "    vocabulary = pickle.load(fp)\n",
    "    \n",
    "vocab_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc355a1a",
   "metadata": {},
   "source": [
    "## Bi-directional LSTM Masked Language Modeling\n",
    "\n",
    "references: \n",
    "\n",
    "https://keras.io/examples/nlp/masked_language_modeling/#create-bert-model-pretraining-model-for-masked-language-modeling\n",
    "\n",
    "https://www.kaggle.com/code/ritvik1909/masked-language-modelling-rnn#Data-Preparation\n",
    "\n",
    "https://keras.io/examples/nlp/bidirectional_lstm_imdb/\n",
    "\n",
    "questions:\n",
    "- should we split data by sentence instead of by fixed window size of 20?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51007c",
   "metadata": {},
   "source": [
    "### more data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "103b3b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert words to vectors\n",
    "vectorized_text = list(map(lambda x: vocabulary[x], train_data))\n",
    "vectorized_text = np.array(vectorized_text)\n",
    "\n",
    "# add [mask] to vocabulary\n",
    "mask_id = vocab_size\n",
    "vocabulary['[mask]'] = mask_id\n",
    "\n",
    "# split data into sequences of length 20\n",
    "vectorized_text_len = len(vectorized_text) - (len(vectorized_text) % 20)\n",
    "vectorized_text = vectorized_text[:vectorized_text_len]\n",
    "vectorized_text = np.reshape(vectorized_text,[-1,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c34a2e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4556,  986, 4556, ..., 1696, 4015,    0],\n",
       "       [ 718, 4250, 3636, ...,    0, 4556, 1095],\n",
       "       [   0, 4556, 4556, ..., 1280, 4556, 4556],\n",
       "       ...,\n",
       "       [1533,  822, 2609, ..., 1954, 1778, 1731],\n",
       "       [1449, 2609,    0, ..., 4556, 2856, 2622],\n",
       "       [4580,    0,  349, ..., 4309, 4556,  165]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f04468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_one_input_label(sequence):\n",
    "    \n",
    "    # randomly choose one position in sequence to mask\n",
    "    mask = np.random.randint(low=0, high=20)\n",
    "    \n",
    "    # add mask to input\n",
    "    masked_input = [token if i != mask else mask_id for i, token in enumerate(sequence)]\n",
    "    \n",
    "    # set all values in label to -1(ignored by loss function) except the value at the masked position\n",
    "    label = [-1 if i!= mask else token for i, token in enumerate(sequence)]\n",
    "    return masked_input, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76fbd678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get masked inputs and labels\n",
    "def get_masked_inputs_labels(text):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for seq in text:\n",
    "        x,y = mask_one_input_label(seq)\n",
    "        inputs.append(x)\n",
    "        labels.append(y)\n",
    "    inputs = np.array(inputs)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return inputs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8dcf54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = get_masked_inputs_labels(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4016fd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4556  986 4556 5001 4556 3012    0 4556 1965  846 4641 1398 3772 3232\n",
      " 2543 1061    0 1696 4015    0] [ -1  -1  -1 389  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1\n",
      "  -1  -1]\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0], labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56a73b",
   "metadata": {},
   "source": [
    "### bi-directional lstm model building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9830fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define masked language modeling class\n",
    "class LSTM_MLM(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embed_size, input_length):\n",
    "        \"\"\"\n",
    "        The Model class predicts the next words in a sequence.\n",
    "        : param vocab_size : The number of unique words in the data\n",
    "        : param hidden_size   : The size of your desired RNN\n",
    "        : param embed_size : The size of your latent embedding\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.input_length = input_length\n",
    "\n",
    "        ## TODO: define your trainable variables and/or layers here. This should include an\n",
    "        ## embedding component, and any other variables/layers you require.\n",
    "\n",
    "        # embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size+1, output_dim=self.embed_size)\n",
    "        self.lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))\n",
    "        self.dense1 = tf.keras.layers.Dense(self.vocab_size, activation='softmax')\n",
    "\n",
    "        # fully connected linear layers\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        You must use an embedding layer as the first layer of your network (i.e. tf.nn.embedding_lookup or tf.keras.layers.Embedding)\n",
    "        :param inputs: word ids of shape (batch_size, 2)\n",
    "        :return: logits: The batch element probabilities as a tensor of shape (batch_size, vocab_size)\n",
    "        \"\"\"\n",
    "\n",
    "        # embedding layer\n",
    "        x = inputs\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = self.lstm(x)\n",
    "        x = self.dense1(x)\n",
    "\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c274c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1104/1104 [==============================] - 272s 241ms/step - loss: 4.9912\n",
      "Epoch 2/20\n",
      "1104/1104 [==============================] - 262s 237ms/step - loss: 4.5843\n",
      "Epoch 3/20\n",
      "1104/1104 [==============================] - 279s 253ms/step - loss: 4.3674\n",
      "Epoch 4/20\n",
      "1104/1104 [==============================] - 430s 389ms/step - loss: 4.1467\n",
      "Epoch 5/20\n",
      "1104/1104 [==============================] - 645s 584ms/step - loss: 3.9180\n",
      "Epoch 6/20\n",
      "1104/1104 [==============================] - 689s 624ms/step - loss: 3.6847\n",
      "Epoch 7/20\n",
      "1104/1104 [==============================] - 778s 705ms/step - loss: 3.4503\n",
      "Epoch 8/20\n",
      "1104/1104 [==============================] - 529s 479ms/step - loss: 3.2179\n",
      "Epoch 9/20\n",
      "1104/1104 [==============================] - 513s 465ms/step - loss: 2.9956\n",
      "Epoch 10/20\n",
      "1104/1104 [==============================] - 512s 464ms/step - loss: 2.7827\n",
      "Epoch 11/20\n",
      "1104/1104 [==============================] - 523s 474ms/step - loss: 2.5808\n",
      "Epoch 12/20\n",
      "1104/1104 [==============================] - 505s 457ms/step - loss: 2.3903\n",
      "Epoch 13/20\n",
      "1104/1104 [==============================] - 560s 507ms/step - loss: 2.2130\n",
      "Epoch 14/20\n",
      "1104/1104 [==============================] - 408s 369ms/step - loss: 2.0471\n",
      "Epoch 15/20\n",
      "1104/1104 [==============================] - 437s 396ms/step - loss: 1.8897\n",
      "Epoch 16/20\n",
      "1104/1104 [==============================] - 256s 232ms/step - loss: 1.7436\n",
      "Epoch 17/20\n",
      "1104/1104 [==============================] - 551s 499ms/step - loss: 1.6072\n",
      "Epoch 18/20\n",
      "1104/1104 [==============================] - 541s 491ms/step - loss: 1.4799\n",
      "Epoch 19/20\n",
      "1104/1104 [==============================] - 304s 275ms/step - loss: 1.3630\n",
      "Epoch 20/20\n",
      "1104/1104 [==============================] - 260s 235ms/step - loss: 1.2535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc7cb52a890>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM_MLM(vocab_size, 64, 20)\n",
    "loss_metric = tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1)\n",
    "# accuracy is not a good measure\n",
    "model.compile(loss=loss_metric, optimizer='adam')\n",
    "model.fit(x=inputs, y=labels, batch_size=100, epochs=20) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beb84f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d638eadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5002, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cce07961",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"bidirectional_lstm_embedding.csv\", embeddings, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b190b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bi_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bi_lstm/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"bi_lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35495986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 14:18:48.343292: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# load model:\n",
    "bi_lstm_model = tf.keras.models.load_model(\"bi_lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a45f2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 20, 5001), dtype=float32, numpy=\n",
       "array([[[9.1585011e-05, 1.3117569e-06, 1.0997366e-05, ...,\n",
       "         1.5732139e-06, 3.8908574e-06, 3.5026821e-04],\n",
       "        [9.1562953e-07, 2.3136870e-04, 8.8943061e-06, ...,\n",
       "         2.0479801e-04, 4.1539955e-05, 7.2520037e-05],\n",
       "        [2.1770304e-01, 4.0949718e-08, 7.1525953e-08, ...,\n",
       "         7.3236592e-08, 1.0938587e-06, 3.3486653e-05],\n",
       "        ...,\n",
       "        [2.5719564e-07, 1.7585068e-06, 6.0397913e-05, ...,\n",
       "         3.0698136e-06, 2.8085655e-05, 7.6608595e-09],\n",
       "        [5.3187246e-06, 1.3355157e-06, 3.8149719e-06, ...,\n",
       "         6.8192338e-07, 7.3317761e-07, 5.0227671e-09],\n",
       "        [1.6297359e-06, 2.8895494e-04, 2.9488765e-05, ...,\n",
       "         2.8555092e-04, 1.3249049e-04, 3.0251442e-06]]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_lstm_model(inputs[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1242dc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LSTM_MLM at 0x7fc7e44d5120>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4294ef",
   "metadata": {},
   "source": [
    "### get predicted probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "79ca807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "\n",
    "def get_predicted_probability(masked_sentence, target_word, model):\n",
    "    masked_sentence = masked_sentence.split(' ')\n",
    "    mask_loc = masked_sentence.index('[mask]')\n",
    "    target_id = vocabulary[target_word]\n",
    "    query_id = [vocabulary[q] for q in masked_sentence]\n",
    "    query_id = tf.expand_dims(query_id, axis=0)\n",
    "    #query_id = tf.keras.utils.pad_sequences(query_id, maxlen=20)\n",
    "\n",
    "    \n",
    "    #print(query_id.shape, query_id)\n",
    "    pred = model.predict(tf.cast(query_id, dtype=tf.int64))[:,mask_loc, target_id]\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "51b26911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "# computing the piror probabilities\n",
    "test_sentence = '[mask] is'\n",
    "is_control = get_predicted_probability(test_sentence, 'she', bi_lstm_model),get_predicted_probability(test_sentence, 'he', bi_lstm_model)\n",
    "\n",
    "test_sentence = '[mask] go to'\n",
    "go_to_control = get_predicted_probability(test_sentence, 'she', bi_lstm_model), get_predicted_probability(test_sentence, 'he', bi_lstm_model)\n",
    "\n",
    "test_sentence = '[mask] like to'\n",
    "like_to_control = get_predicted_probability(test_sentence, 'she', bi_lstm_model), get_predicted_probability(test_sentence, 'he', bi_lstm_model)\n",
    "\n",
    "test_sentence = '[mask] like'\n",
    "like_control = get_predicted_probability(test_sentence, 'she', bi_lstm_model), get_predicted_probability(test_sentence, 'he', bi_lstm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1c2e94e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([5.183443e-05], dtype=float32), array([0.00030025], dtype=float32)) (array([0.00014551], dtype=float32), array([0.00217571], dtype=float32)) (array([0.01150292], dtype=float32), array([0.03890121], dtype=float32)) (array([0.00222062], dtype=float32), array([0.01342267], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(is_control, go_to_control, like_to_control, like_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b4b01448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predicted_prob(test_sentence, control, model):\n",
    "    print(test_sentence, '| she: ',get_predicted_probability(test_sentence, 'she', model) / control[0], 'he: ',get_predicted_probability(test_sentence, 'he', model) / control[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fd046776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[mask] is brave | she:  [0.2842527] he:  [5.285549]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[mask] go to adventure | she:  [2.7535584] he:  [6.393502]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[mask] is dancer | she:  [3.713658] he:  [3.498644]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[mask] is powerful | she:  [0.4792545] he:  [1.0384507]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[mask] defend kingdom [0.00012739] [0.01688957]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[mask] like flower | she:  [5.0011287] he:  [0.43901497]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[mask] is evil | she:  [10.290385] he:  [4.77123]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[mask] clean house [0.00496159] [0.00163339]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[mask] is farmer | she:  [0.55351114] he:  [0.33463782]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[mask] is doctor | she:  [1.6848944] he:  [0.04227228]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = '[mask] is brave'\n",
    "print(test_sentence, '| she: ',get_predicted_probability(test_sentence, 'she', bi_lstm_model) / is_control[0], 'he: ',get_predicted_probability(test_sentence, 'he', bi_lstm_model) / is_control[1])\n",
    "\n",
    "test_sentence = '[mask] go to adventure'\n",
    "print(test_sentence, '| she: ',get_predicted_probability(test_sentence, 'she', bi_lstm_model) / go_to_control[0], 'he: ',get_predicted_probability(test_sentence, 'he', bi_lstm_model) / go_to_control[1])\n",
    "\n",
    "test_sentence = '[mask] is dancer'\n",
    "print(test_sentence, '| she: ',get_predicted_probability(test_sentence, 'she', bi_lstm_model) / is_control[0], 'he: ',get_predicted_probability(test_sentence, 'he', bi_lstm_model) / is_control[1])\n",
    "\n",
    "test_sentence = '[mask] is powerful'\n",
    "calculate_predicted_prob(test_sentence, is_control, bi_lstm_model)\n",
    "\n",
    "test_sentence = '[mask] defend kingdom'\n",
    "print(test_sentence, get_predicted_probability(test_sentence, 'she', bi_lstm_model),get_predicted_probability(test_sentence, 'he', bi_lstm_model))\n",
    "\n",
    "test_sentence = '[mask] like flower'\n",
    "calculate_predicted_prob(test_sentence, like_control, bi_lstm_model)\n",
    "#print(get_predicted_probability(test_sentence, 'she', bi_lstm_model),get_predicted_probability(test_sentence, 'he', bi_lstm_model))\n",
    "\n",
    "test_sentence = '[mask] is evil'\n",
    "calculate_predicted_prob(test_sentence, is_control, bi_lstm_model)\n",
    "#print(get_predicted_probability(test_sentence, 'she', bi_lstm_model),get_predicted_probability(test_sentence, 'he', bi_lstm_model))\n",
    "\n",
    "\n",
    "test_sentence = '[mask] clean house'\n",
    "print(test_sentence, get_predicted_probability(test_sentence, 'she', bi_lstm_model),get_predicted_probability(test_sentence, 'he', bi_lstm_model))\n",
    "\n",
    "test_sentence = '[mask] is farmer'\n",
    "calculate_predicted_prob(test_sentence, is_control, bi_lstm_model)\n",
    "\n",
    "test_sentence = '[mask] is doctor'\n",
    "calculate_predicted_prob(test_sentence, is_control, bi_lstm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "48e2c4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[mask] is brave | she:  [1.2916332] he:  [4.377674]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[mask] go to adventure | she:  [0.03073567] he:  [12.820654]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[mask] is dancer | she:  [0.7502615] he:  [3.8066258]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[mask] is powerful | she:  [4.3927627] he:  [9.716445]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[mask] defend kingdom [0.0148472] [0.01306464]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[mask] like flower | she:  [0.03776532] he:  [0.64926606]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[mask] is evil | she:  [15.690093] he:  [5.5144444]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[mask] clean house [0.0032139] [0.00334156]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[mask] is farmer | she:  [0.10256335] he:  [11.241835]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[mask] is doctor | she:  [0.47087517] he:  [22.042593]\n"
     ]
    }
   ],
   "source": [
    "# do predictions for transformer model\n",
    "\n",
    "test_sentence = '[mask] is brave'\n",
    "print(test_sentence, '| she: ',get_predicted_probability(test_sentence, 'she', transformer_model) / is_control[0], 'he: ',get_predicted_probability(test_sentence, 'he', transformer_model) / is_control[1])\n",
    "\n",
    "test_sentence = '[mask] go to adventure'\n",
    "print(test_sentence, '| she: ',get_predicted_probability(test_sentence, 'she', transformer_model) / go_to_control[0], 'he: ',get_predicted_probability(test_sentence, 'he', transformer_model) / go_to_control[1])\n",
    "\n",
    "test_sentence = '[mask] is dancer'\n",
    "print(test_sentence, '| she: ',get_predicted_probability(test_sentence, 'she', transformer_model) / is_control[0], 'he: ',get_predicted_probability(test_sentence, 'he', transformer_model) / is_control[1])\n",
    "\n",
    "test_sentence = '[mask] is powerful'\n",
    "calculate_predicted_prob(test_sentence, is_control, transformer_model)\n",
    "\n",
    "test_sentence = '[mask] defend kingdom'\n",
    "print(test_sentence, get_predicted_probability(test_sentence, 'she', transformer_model),get_predicted_probability(test_sentence, 'he', transformer_model))\n",
    "\n",
    "test_sentence = '[mask] like flower'\n",
    "calculate_predicted_prob(test_sentence, like_control, transformer_model)\n",
    "#print(get_predicted_probability(test_sentence, 'she', transformer_model),get_predicted_probability(test_sentence, 'he', transformer_model))\n",
    "\n",
    "test_sentence = '[mask] is evil'\n",
    "calculate_predicted_prob(test_sentence, is_control, transformer_model)\n",
    "#print(get_predicted_probability(test_sentence, 'she', transformer_model),get_predicted_probability(test_sentence, 'he', transformer_model))\n",
    "\n",
    "\n",
    "test_sentence = '[mask] clean house'\n",
    "print(test_sentence, get_predicted_probability(test_sentence, 'she', transformer_model),get_predicted_probability(test_sentence, 'he', transformer_model))\n",
    "\n",
    "test_sentence = '[mask] is farmer'\n",
    "calculate_predicted_prob(test_sentence, is_control, transformer_model)\n",
    "\n",
    "test_sentence = '[mask] is doctor'\n",
    "calculate_predicted_prob(test_sentence, is_control, transformer_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b64fc2d",
   "metadata": {},
   "source": [
    "### access embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0ef8cd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4127, 64)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.layers[0].get_weights()[0]\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed693a",
   "metadata": {},
   "source": [
    "### testing lstm model on HW4 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f9ab1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../data/hw4_train.txt', \"r\")\n",
    "\n",
    "hw4_data = file.read()\n",
    "hw4_data = hw4_data.replace('\\n', ' ').split(' ')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c71b8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw4_vocabulary, hw4_vocab_size = get_vocab(hw4_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b88121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert words to vectors\n",
    "hw4_vectorized_text = list(map(lambda x: hw4_vocabulary[x], hw4_data))\n",
    "hw4_vectorized_text = np.array(hw4_vectorized_text)\n",
    "\n",
    "# add [mask] to vocabulary\n",
    "mask_id = vocab_size\n",
    "hw4_vocabulary['[mask]'] = mask_id\n",
    "\n",
    "# split data into sequences of length 20\n",
    "hw4_vectorized_text_len = len(hw4_vectorized_text) - (len(hw4_vectorized_text) % 20)\n",
    "hw4_vectorized_text = hw4_vectorized_text[:hw4_vectorized_text_len]\n",
    "hw4_vectorized_text = np.reshape(hw4_vectorized_text,[-1,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d5989da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw4_inputs, hw4_labels = get_masked_inputs_labels(hw4_vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0e7a53e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing model performance on hw4 data:\n",
    "# model = LSTM_MLM(hw4_vocab_size, 64, 20)\n",
    "# loss_metric = tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1)\n",
    "# model.compile(loss=loss_metric, optimizer='adam')\n",
    "# model.fit(x=hw4_inputs, y=hw4_labels, batch_size=20, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696ff06",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238aa8ac",
   "metadata": {},
   "source": [
    "references: \"Attention Is All You Need\" paper by Vaswani et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e923d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model):\n",
    "        super(SingleHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.query = tf.keras.layers.Dense(d_model)\n",
    "        self.key = tf.keras.layers.Dense(d_model)\n",
    "        self.value = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, q, k, v, mask):\n",
    "        q = self.query(q)\n",
    "        k = self.key(k)\n",
    "        v = self.value(v)\n",
    "        \n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(dk)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32f12b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.att = SingleHeadAttention(d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(d_model * 4, activation='relu'),\n",
    "            tf.keras.layers.Dense(d_model)\n",
    "        ])\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.1)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.1)\n",
    "\n",
    "    def call(self, x, training, mask=None):\n",
    "        attn_output, _ = self.att(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f22cb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_MLM(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embed_size, input_length):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.input_length = input_length\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size+1, output_dim=self.embed_size)\n",
    "        self.transformer_block = TransformerBlock(self.embed_size)\n",
    "        self.dense1 = tf.keras.layers.Dense(self.vocab_size, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer_block(x, training=True)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64138dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1104/1104 [==============================] - 94s 83ms/step - loss: 4.9639\n",
      "Epoch 2/20\n",
      "1104/1104 [==============================] - 93s 84ms/step - loss: 4.6655\n",
      "Epoch 3/20\n",
      "1104/1104 [==============================] - 98s 89ms/step - loss: 4.5098\n",
      "Epoch 4/20\n",
      "1104/1104 [==============================] - 100s 91ms/step - loss: 4.3153\n",
      "Epoch 5/20\n",
      "1104/1104 [==============================] - 95s 86ms/step - loss: 4.0986\n",
      "Epoch 6/20\n",
      "1104/1104 [==============================] - 103s 93ms/step - loss: 3.8871\n",
      "Epoch 7/20\n",
      "1104/1104 [==============================] - 92s 83ms/step - loss: 3.6933\n",
      "Epoch 8/20\n",
      "1104/1104 [==============================] - 101s 92ms/step - loss: 3.5120\n",
      "Epoch 9/20\n",
      "1104/1104 [==============================] - 2973s 3s/step - loss: 3.3529\n",
      "Epoch 10/20\n",
      "1104/1104 [==============================] - 212s 192ms/step - loss: 3.2107\n",
      "Epoch 11/20\n",
      "1104/1104 [==============================] - 200s 181ms/step - loss: 3.0850\n",
      "Epoch 12/20\n",
      "1104/1104 [==============================] - 190s 172ms/step - loss: 2.9731\n",
      "Epoch 13/20\n",
      "1104/1104 [==============================] - 1195s 1s/step - loss: 2.8771\n",
      "Epoch 14/20\n",
      "1104/1104 [==============================] - 4732s 4s/step - loss: 2.7880\n",
      "Epoch 15/20\n",
      "1104/1104 [==============================] - 9188s 8s/step - loss: 2.7096\n",
      "Epoch 16/20\n",
      "1104/1104 [==============================] - 3796s 3s/step - loss: 2.6403\n",
      "Epoch 17/20\n",
      "1104/1104 [==============================] - 1180s 1s/step - loss: 2.5826\n",
      "Epoch 18/20\n",
      "1104/1104 [==============================] - 256s 232ms/step - loss: 2.5288\n",
      "Epoch 19/20\n",
      "1104/1104 [==============================] - 198s 179ms/step - loss: 2.4700\n",
      "Epoch 20/20\n",
      "1104/1104 [==============================] - 204s 185ms/step - loss: 2.4287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13723ead0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t = Transformer_MLM(vocab_size, 64, 20)\n",
    "loss_metric = tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1)\n",
    "model_t.compile(loss=loss_metric, optimizer='adam')\n",
    "model_t.fit(x=inputs, y=labels, batch_size=100, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "649d5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_t = model_t.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20289b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5002, 64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c128073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"transformer_embedding.csv\", embeddings_t, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fac6bc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, single_head_attention_1_layer_call_fn, single_head_attention_1_layer_call_and_return_conditional_losses, layer_normalization_2_layer_call_fn, layer_normalization_2_layer_call_and_return_conditional_losses while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: transformer/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: transformer/assets\n"
     ]
    }
   ],
   "source": [
    "model_t.save(\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7798bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model:\n",
    "transformer_model = tf.keras.models.load_model(\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c670ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 20, 5001), dtype=float32, numpy=\n",
       "array([[[7.20110312e-02, 7.79032600e-19, 1.70412761e-07, ...,\n",
       "         1.00463919e-12, 1.00197151e-12, 1.45546159e-13],\n",
       "        [6.59962371e-02, 2.29241464e-18, 8.37374472e-08, ...,\n",
       "         5.34724912e-12, 5.02420208e-13, 1.01960195e-13],\n",
       "        [1.05563268e-01, 2.09895659e-19, 1.01196427e-07, ...,\n",
       "         1.11461899e-13, 2.12502693e-12, 9.00668700e-13],\n",
       "        ...,\n",
       "        [1.43963531e-01, 2.24087178e-18, 5.96755640e-08, ...,\n",
       "         4.98968488e-12, 2.96021172e-12, 3.41184095e-11],\n",
       "        [7.87760988e-02, 7.08022029e-16, 4.88780233e-06, ...,\n",
       "         1.66679504e-10, 3.28379858e-11, 3.20182457e-11],\n",
       "        [2.88114119e-02, 6.79120185e-14, 9.41598319e-06, ...,\n",
       "         5.85992421e-10, 5.75283687e-09, 5.43263545e-10]]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_model(inputs[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "050658fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = '[mask] like beautiful dress'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4b68087",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'transformer_mlm_1' (type Transformer_MLM).\n    \n    Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (1 total):\n        * <tf.Tensor 'inputs:0' shape=(None, 4) dtype=int64>\n      Keyword arguments: {'training': False}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (1 total):\n        * TensorSpec(shape=(None, 20), dtype=tf.int64, name='inputs')\n      Keyword arguments: {'training': False}\n    \n    Option 2:\n      Positional arguments (1 total):\n        * TensorSpec(shape=(None, 20), dtype=tf.int64, name='inputs')\n      Keyword arguments: {'training': True}\n    \n    Option 3:\n      Positional arguments (1 total):\n        * TensorSpec(shape=(None, 20), dtype=tf.int64, name='input_1')\n      Keyword arguments: {'training': False}\n    \n    Option 4:\n      Positional arguments (1 total):\n        * TensorSpec(shape=(None, 20), dtype=tf.int64, name='input_1')\n      Keyword arguments: {'training': True}\n    \n    Call arguments received by layer 'transformer_mlm_1' (type Transformer_MLM):\n      • args=('tf.Tensor(shape=(None, 4), dtype=int64)',)\n      • kwargs=<class 'inspect._empty'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_predicted_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m, in \u001b[0;36mget_predicted_probability\u001b[0;34m(masked_sentence, target_word, model)\u001b[0m\n\u001b[1;32m     10\u001b[0m query_id \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(query_id, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#print(query_id.shape, query_id)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[:,mask_loc, target_id]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "File \u001b[0;32m/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/3h/rwm3946s6m393kd1m_w94xl00000gn/T/__autograph_generated_filehpijsmdw.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'transformer_mlm_1' (type Transformer_MLM).\n    \n    Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (1 total):\n        * <tf.Tensor 'inputs:0' shape=(None, 4) dtype=int64>\n      Keyword arguments: {'training': False}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (1 total):\n        * TensorSpec(shape=(None, 20), dtype=tf.int64, name='inputs')\n      Keyword arguments: {'training': False}\n    \n    Option 2:\n      Positional arguments (1 total):\n        * TensorSpec(shape=(None, 20), dtype=tf.int64, name='inputs')\n      Keyword arguments: {'training': True}\n    \n    Option 3:\n      Positional arguments (1 total):\n        * TensorSpec(shape=(None, 20), dtype=tf.int64, name='input_1')\n      Keyword arguments: {'training': False}\n    \n    Option 4:\n      Positional arguments (1 total):\n        * TensorSpec(shape=(None, 20), dtype=tf.int64, name='input_1')\n      Keyword arguments: {'training': True}\n    \n    Call arguments received by layer 'transformer_mlm_1' (type Transformer_MLM):\n      • args=('tf.Tensor(shape=(None, 4), dtype=int64)',)\n      • kwargs=<class 'inspect._empty'>\n"
     ]
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence, 'she', transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f62b708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00011386], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence, 'she', model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fabc4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0017492], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence, 'he', model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbcd1d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.09520493], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence, 'queen', model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58a2f92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00025578], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence, 'king', model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05370c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence_evil = 'evil old [mask]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fad39011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02564601], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence_evil, 'man', model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ec8c697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.04206395], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence_evil, 'woman', model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b4a0abc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([6.268294e-05], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_brave = 'brave [mask]'\n",
    "get_predicted_probability(test_brave, 'woman', model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "106fc6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03903314], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_brave, 'man', model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "114d1f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([6.4778555e-06], dtype=float32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_power = 'powerful [mask]'\n",
    "get_predicted_probability(test_power, 'woman', model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05b4710e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.01902533], dtype=float32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_brave, 'man', model_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
